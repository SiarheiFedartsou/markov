{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv('./abcnews-date-text.csv')\n",
    "data = d#[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1103665"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1103660</th>\n",
       "      <td>20171231</td>\n",
       "      <td>the ashes smiths warners near miss liven up bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103661</th>\n",
       "      <td>20171231</td>\n",
       "      <td>timelapse: brisbanes new year fireworks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103662</th>\n",
       "      <td>20171231</td>\n",
       "      <td>what 2017 meant to the kids of australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103663</th>\n",
       "      <td>20171231</td>\n",
       "      <td>what the papodopoulos meeting may mean for ausus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103664</th>\n",
       "      <td>20171231</td>\n",
       "      <td>who is george papadopoulos the former trump ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         publish_date                                      headline_text\n",
       "1103660      20171231  the ashes smiths warners near miss liven up bo...\n",
       "1103661      20171231            timelapse: brisbanes new year fireworks\n",
       "1103662      20171231           what 2017 meant to the kids of australia\n",
       "1103663      20171231   what the papodopoulos meeting may mean for ausus\n",
       "1103664      20171231  who is george papadopoulos the former trump ca..."
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadlineGenerator(object):\n",
    "    def save(self, file_name):\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            pickle.dump({\"pi\": self._pi, \"second\": self._second, \"a\": self._a}, f)\n",
    "    def load(self, file_name):\n",
    "        with open(file_name, \"rb\") as f:\n",
    "            params = pickle.load(f)\n",
    "            self._pi = params[\"pi\"]\n",
    "            self._second = params[\"second\"]\n",
    "            self._a = params[\"a\"]\n",
    "    \n",
    "    def _probabilities(self, tokens):\n",
    "        n = len(tokens)\n",
    "        probs = {}\n",
    "        for token in tokens:\n",
    "            probs[token] = probs.get(token, 0.) + 1\n",
    "        for token, count in probs.items():\n",
    "            probs[token] = count / n\n",
    "        return probs\n",
    "    \n",
    "    def fit(self, headlines):\n",
    "        initial = {}\n",
    "        second = {}\n",
    "        A = {}\n",
    "        \n",
    "        tokenized_headlines = [wordpunct_tokenize(headline) for headline in headlines]\n",
    "        for headline in tokenized_headlines:\n",
    "            word0 = headline[0]\n",
    "            initial[word0] = initial.get(word0, 0) + 1\n",
    "            \n",
    "            if not len(headline) > 1:\n",
    "                second[word0] = second.get(word0, []) + [\"<END>\"]\n",
    "                continue\n",
    "            \n",
    "            word1 = headline[1]\n",
    "            second[word0] = second.get(word0, []) + [word1]\n",
    "            \n",
    "            for idx in range(2, len(headline)):\n",
    "                word = headline[idx]\n",
    "                A[(word0, word1)] = A.get((word0, word1), []) + [word]\n",
    "                word0 = word1\n",
    "                word1 = word\n",
    "            A[(word0, word1)] = A.get((word0, word1), []) + [\"<END>\"]\n",
    "            \n",
    "        \n",
    "        for state, tokens in initial.items():\n",
    "            initial[state] = initial[state] / len(headlines)\n",
    "        for state, tokens in second.items():\n",
    "            second[state] = self._probabilities(tokens)\n",
    "        for state, tokens in A.items():\n",
    "            A[state] = self._probabilities(tokens)\n",
    "        \n",
    "        self._pi = initial\n",
    "        self._second = second\n",
    "        self._a = A\n",
    "    \n",
    "    def _get_random_token(self, d):\n",
    "        return np.random.choice(list(d.keys()), p = list(d.values()))\n",
    "    \n",
    "    def generate(self, random_state):\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "        words = [self._get_random_token(self._pi)]\n",
    "        words += [self._get_random_token(self._second[words[0]])]\n",
    "        \n",
    "        while words[-1] != \"<END>\":\n",
    "            prev_words = (words[-2], words[-1])\n",
    "            words += [self._get_random_token(self._a[prev_words])]\n",
    "            \n",
    "            \n",
    "        \n",
    "        return ' '.join(words[:-1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = HeadlineGenerator()\n",
    "generator.fit(data.headline_text)\n",
    "generator.save(\"markov_model.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = HeadlineGenerator()\n",
    "generator.load(\"markov_model.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'freo fans prepare for clarence council to reduce wrongful convictions under abolished laws'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.generate(random_state = 4200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
